{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pmdarima.arima import auto_arima\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tsfresh\n",
    "from pmdarima.arima import ADFTest\n",
    "from tsfresh import extract_features\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = read_csv(\"../../Time_series_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01</td>\n",
       "      <td>2815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02</td>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03</td>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04</td>\n",
       "      <td>2721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-06</td>\n",
       "      <td>3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-07</td>\n",
       "      <td>2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-08</td>\n",
       "      <td>2212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-09</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-10</td>\n",
       "      <td>4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-11</td>\n",
       "      <td>5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-12</td>\n",
       "      <td>7312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-01</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  Sales\n",
       "0   2013-01   2815\n",
       "1   2013-02   2672\n",
       "2   2013-03   2755\n",
       "3   2013-04   2721\n",
       "4   2013-05   2946\n",
       "5   2013-06   3036\n",
       "6   2013-07   2282\n",
       "7   2013-08   2212\n",
       "8   2013-09   2922\n",
       "9   2013-10   4301\n",
       "10  2013-11   5764\n",
       "11  2013-12   7312\n",
       "12  2014-01   2541"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = values.rename(columns={values.columns[1]: 'Data'})\n",
    "values = values.rename(columns={values.columns[0]: 'Time'})\n",
    "values['Time'] = pd.to_datetime(\n",
    "    values['Time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.infer_freq(values[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_date = pd.to_datetime(x) + pd.DateOffset(months=10)\n",
    "# print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.set_index('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(\n",
    "    values, test_size=0.2, shuffle=False)\n",
    "\n",
    "rnn_train = train\n",
    "rnn_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(rnn_train)\n",
    "scaled_train = scaler.transform(rnn_train)\n",
    "scaled_test = scaler.transform(rnn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# define generator\n",
    "n_input = 12\n",
    "n_features = 1\n",
    "generator = TimeseriesGenerator(\n",
    "    scaled_train, scaled_train, length=n_input, batch_size=1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40901 (159.77 KB)\n",
      "Trainable params: 40901 (159.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 2s 4ms/step - loss: 0.0589\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0442\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0356\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0244\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0252\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0416\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0256\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0142\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0104\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0148\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0086\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e211664790>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu',\n",
    "            input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "model.fit(generator, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = scaled_train[-12:]\n",
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08636474],\n",
       "        [0.10742931],\n",
       "        [0.14558859],\n",
       "        [0.1755651 ],\n",
       "        [0.1096978 ],\n",
       "        [0.19549542],\n",
       "        [0.21421048],\n",
       "        [0.0133679 ],\n",
       "        [0.29555213],\n",
       "        [0.39301628],\n",
       "        [0.66993438],\n",
       "        [0.93194523]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n"
     ]
    }
   ],
   "source": [
    "model.predict(last_train_batch)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_train[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40901 (159.77 KB)\n",
      "Trainable params: 40901 (159.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rnn_test)):\n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "\n",
    "    # append the prediction into the array\n",
    "    test_predictions.append(current_pred)\n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:, 1:, :], [\n",
    "                                [current_pred]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.48265636],\n",
       "        [0.69599384],\n",
       "        [0.83337021],\n",
       "        [0.2187189 ],\n",
       "        [0.20008415],\n",
       "        [0.20542215],\n",
       "        [0.21479109],\n",
       "        [0.20265721],\n",
       "        [0.24025083],\n",
       "        [0.26893696],\n",
       "        [0.22624701],\n",
       "        [0.41539305]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(test_predictions)\n",
    "rnn_test['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_errors = [rnn_test['Data'][i]-rnn_test['Predictions'][i] for i in range(len(rnn_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[179.9218740016222,\n",
       " -517.9855819344521,\n",
       " 425.45999559760094,\n",
       " 629.2033453434706,\n",
       " 1321.5106441825628,\n",
       " 577.4984444379807,\n",
       " 75.96219836175442,\n",
       " -1800.039199128747,\n",
       " -22.753655791282654,\n",
       " -549.42744743824,\n",
       " -312.6519756913185,\n",
       " 810.7115135192871,\n",
       " 75.35260154306889,\n",
       " -478.63866144418716,\n",
       " 468.4744258970022,\n",
       " 563.8335848152637,\n",
       " 543.6020835489035,\n",
       " 773.5840561389923,\n",
       " -594.4889205992222,\n",
       " -2952.566876709461,\n",
       " -823.1964715123177]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_forecast_error = np.mean(forecast_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690.3268360779399"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(rnn_test['Data'], rnn_test['Predictions'])\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889314.2211560281"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(rnn_test['Data'], rnn_test['Predictions'])\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2432546575620112"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(rnn_test['Data'], rnn_test['Predictions'])\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n",
      "   Age  Gender    Income\n",
      "0   25       1 -0.697486\n",
      "1   30       0  0.464991\n",
      "2   22       1 -1.278724\n",
      "3   35       0  1.627467\n",
      "4   28       1 -0.116248\n",
      "Training Data:\n",
      "   Age  Gender    Income\n",
      "0   25       1 -0.697486\n",
      "1   30       0  0.464991\n",
      "2   22       1 -1.278724\n",
      "Testing Data:\n",
      "   Age  Gender    Income\n",
      "3   35       0  1.627467\n",
      "4   28       1 -0.116248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Tạo một DataFrame giả định\n",
    "data = pd.DataFrame({\n",
    "    'Age': [25, 30, 22, 35, 28],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000]\n",
    "})\n",
    "\n",
    "# Data Preprocessing - Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "data['Income'] = scaler.fit_transform(data[['Income']])\n",
    "\n",
    "# Data Preprocessing - Mã hóa biến phân loại\n",
    "encoder = LabelEncoder()\n",
    "data['Gender'] = encoder.fit_transform(data['Gender'])\n",
    "\n",
    "# Data Preparation - Tạo tập huấn luyện và kiểm tra\n",
    "train_data = data.iloc[:3]  # Dữ liệu huấn luyện\n",
    "test_data = data.iloc[3:]   # Dữ liệu kiểm tra\n",
    "\n",
    "print(\"Preprocessed Data:\")\n",
    "print(data)\n",
    "print(\"Training Data:\")\n",
    "print(train_data)\n",
    "print(\"Testing Data:\")\n",
    "print(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nckh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
